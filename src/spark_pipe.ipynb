{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init spark session and context\n",
    "\n",
    "import pyspark as ps\n",
    "\n",
    "spark = ps.sql.SparkSession.builder \\\n",
    "            .appName(\"quora questions\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages to pull data from AWS S3 bucket\n",
    "\n",
    "import boto\n",
    "import boto.s3.connection\n",
    "\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in AWS access keys\n",
    "\n",
    "try:\n",
    "    access_key = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "    secret_key = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "\n",
    "except:\n",
    "    import json\n",
    "    with open('/home/hadoop/amazon.json') as key_file:\n",
    "        keys = json.load(key_file)\n",
    "        access_key = keys[\"AWS_ACCESS_KEY_ID\"]\n",
    "        secret_key = keys[\"AWS_SECRET_ACCESS_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "('Passed --- ', 'train.csv')\n"
     ]
    }
   ],
   "source": [
    "bucket_name = \"quora-bwl\"\n",
    "conn = boto.connect_s3(access_key, secret_key, host='s3.amazonaws.com')\n",
    "bucket = conn.get_bucket(bucket_name)\n",
    "\n",
    "\n",
    "key = bucket.get_key('train.csv')\n",
    "\n",
    "print (key.ongoing_restore)\n",
    "\n",
    "file_name = str(key.name).split('/')[-1]\n",
    "\n",
    "try:\n",
    "    key.get_contents_to_filename(file_name)\n",
    "    print ('Passed --- ', file_name)\n",
    "except:\n",
    "    print ('Failed --- ', file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile('train.csv') \\\n",
    "    .map(lambda l: l.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'\"id\"',\n",
       "  u'\"qid1\"',\n",
       "  u'\"qid2\"',\n",
       "  u'\"question1\"',\n",
       "  u'\"question2\"',\n",
       "  u'\"is_duplicate\"'],\n",
       " [u'\"0\"',\n",
       "  u'\"1\"',\n",
       "  u'\"2\"',\n",
       "  u'\"What is the step by step guide to invest in share market in india?\"',\n",
       "  u'\"What is the step by step guide to invest in share market?\"',\n",
       "  u'\"0\"']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
